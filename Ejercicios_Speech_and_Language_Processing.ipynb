{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Solutions**\n",
        "https://github.com/Clement25/Speech-and-Language-Processing-ver3-solutions"
      ],
      "metadata": {
        "id": "xW3ZCz0OrQ9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cap 3**"
      ],
      "metadata": {
        "id": "D5E46kVBY3ef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 creation of N gram"
      ],
      "metadata": {
        "id": "S4-0oPfvY831"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepro_text(text):\n",
        "  text = text.strip().split(' ')\n",
        "  text = [n for n in text if n != ' ']\n",
        "\n",
        "  if text[0] != '<s>': text.insert(0, '<s>')\n",
        "  if text[-1] != '</s>': text.insert(len(text), '</s>')\n",
        "  \n",
        "  return text\n",
        "\n",
        "def add_one(dic, key):\n",
        "  if key in dic.keys():\n",
        "    dic[key] += 1\n",
        "  else:\n",
        "    dic[key] = 1\n",
        "  return dic\n",
        "\n",
        "def create_ngram(text, i, N):\n",
        "  combinacion = []\n",
        "  for n in reversed(range(1, N)):\n",
        "    token = [text[i-n] if i-n > -1 else '<s>'][0]\n",
        "    combinacion.append(token)\n",
        "  combinacion = ' '.join(combinacion)\n",
        "  return combinacion\n",
        "\n",
        "def n_gram(w_h, text):\n",
        "  text = prepro_text(text)\n",
        "\n",
        "  w_h = w_h.strip().split(' ')\n",
        "  N = len(w_h)+1\n",
        "\n",
        "  palabras_antes = {}\n",
        "  palabras_proba = {}\n",
        "\n",
        "  combinacion = []\n",
        "  for i, x in enumerate(text):\n",
        "    combinacion = create_ngram(text, i, N)\n",
        "    if w_h == combinacion.split(' '):\n",
        "      palabras_antes = add_one(palabras_antes, x)\n",
        "\n",
        "  for pal in palabras_antes:\n",
        "    numerador = palabras_antes[pal]\n",
        "    denominador = text.count(pal)\n",
        "    palabras_proba[pal] = numerador/denominador\n",
        "  try:\n",
        "    return max(palabras_proba, key=palabras_proba.get)\n",
        "  except:\n",
        "    return '</s>'"
      ],
      "metadata": {
        "id": "QH_ORag_m24u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'me llamo Felipe porque sandia no es sandia no es es y no me llamo Felipe pero se llama Felipe pero no me llamo Jose pero no se llama Jose llama Jose llama Jose y sandia es'\n",
        "w_h = 'sandia'\n",
        "\n",
        "for i in range(15):\n",
        "  print(w_h)\n",
        "  w_h = n_gram(w_h, text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hoVPbtFe_MU",
        "outputId": "b6edd048-8fb1-4e8a-a289-5b2f56f9cfa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sandia\n",
            "no\n",
            "me\n",
            "llamo\n",
            "Felipe\n",
            "porque\n",
            "sandia\n",
            "no\n",
            "me\n",
            "llamo\n",
            "Felipe\n",
            "porque\n",
            "sandia\n",
            "no\n",
            "me\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2"
      ],
      "metadata": {
        "id": "YY9BrfbsxOpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i_start = 0.25\n",
        "want_i = 0.33\n",
        "chinese_want = 0.0065\n",
        "food_chinese = 0.52\n",
        "end_food = 0.68\n",
        "\n",
        "res_uno = i_start * want_i * chinese_want * food_chinese * end_food * 1000"
      ],
      "metadata": {
        "id": "ze8XmEQyxPz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_one_smooth(wn_1, w1, v):\n",
        "  return ((wn_1 + 1) * w1) / (w1 + v)"
      ],
      "metadata": {
        "id": "uP6QQXp-zRQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.4"
      ],
      "metadata": {
        "id": "4gkBAp0bw03z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(text):\n",
        "  new = ''\n",
        "  for n in text:\n",
        "    new += n+' '\n",
        "  return new"
      ],
      "metadata": {
        "id": "TF_xBjpg11HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bigram(w_n, text, smooth = False):\n",
        "\n",
        "  if smooth:\n",
        "    add = 1\n",
        "    V = len(set(prepro_text(flatten(text))))\n",
        "  else:\n",
        "    add = 0\n",
        "    V = 0\n",
        "\n",
        "  palabras_antes = {}\n",
        "  palabras_proba = {}\n",
        "\n",
        "  for sent in text:\n",
        "    sent = prepro_text(sent)\n",
        "    for i in range(len(sent)-1):\n",
        "      if w_n == sent[i]:\n",
        "        palabras_antes = add_one(palabras_antes, sent[i+1])\n",
        "\n",
        "  for pal in palabras_antes:\n",
        "    numerador = palabras_antes[pal]\n",
        "    denominador = prepro_text(flatten(text)).count(w_n)\n",
        "    palabras_proba[pal] = (numerador + add)/(denominador + V)\n",
        "  try:\n",
        "    result = max(palabras_proba, key=palabras_proba.get)\n",
        "    print(f'Prob: {palabras_proba[result]}')\n",
        "    return result\n",
        "  except:\n",
        "    return '</s>'"
      ],
      "metadata": {
        "id": "E9qUokiWtdc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['<s> I am Sam </s>','<s> Sam I am </s>', '<s> I am Sam </s>', '<s> I do not like green eggs and Sam </s>']\n",
        "bigram('green', text, smooth = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "srix4clixiUI",
        "outputId": "9d97cc0b-4c00-42bf-fb10-d5b08cacb7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prob: 0.16666666666666666\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eggs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add1smooth(text, pre, act):\n",
        "\n",
        "  V = len(set(prepro_text(flatten(text))))\n",
        "  N = 0\n",
        "  match = 0\n",
        "\n",
        "  for sent in text:\n",
        "    sent = prepro_text(sent)\n",
        "    for i in range(len(sent)-1):\n",
        "      if sent[i] == pre:\n",
        "        N += 1\n",
        "        if sent[i+1] == act:\n",
        "          match += 1\n",
        "\n",
        "  return (match + 1) / (N + V)"
      ],
      "metadata": {
        "id": "8rlyU-vCal8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['<s> I am Sam </s>','<s> Sam I am </s>', '<s> I am Sam </s>', '<s> I do not like green eggs and Sam </s>']\n",
        "add1smooth(text, 'green', 'eggs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-57fFrphjOd",
        "outputId": "163bf4b1-5db9-41cf-ac0b-e219654040db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.5"
      ],
      "metadata": {
        "id": "TIae-7y7fVKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['<s> a b', '<s> b b', '<s> b a', '<s> a a']\n",
        "\n",
        "combinations = [['a', 'b'], ['b', 'a'], ['a', 'a'], ['b', 'b']]\n",
        "\n",
        "sumar = 0\n",
        "for c in combinations:\n",
        "  sumar += add1smooth(text, c[0], c[1])\n",
        "\n",
        "sumar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUPkaM7Pe8IU",
        "outputId": "a410546f-f51d-4eb4-b8fb-bb52bf033cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.6"
      ],
      "metadata": {
        "id": "XzpNHfRQmWI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import collections\n",
        "def unigram(sents):\n",
        "    ug_count_dic = collections.defaultdict(int)\n",
        "    ug_prob_dic = collections.defaultdict(float)\n",
        "    total = len(prepro_text(flatten(text)))\n",
        "    for sent in sents:\n",
        "        for word in sent.split(' '):\n",
        "            if word not in ug_count_dic:\n",
        "                ug_count_dic[word] = 1\n",
        "            else:\n",
        "                ug_count_dic[word] += 1\n",
        "        for word in ug_count_dic:\n",
        "            ug_prob_dic[word] = ug_count_dic[word]/total\n",
        "    return ug_count_dic, ug_prob_dic"
      ],
      "metadata": {
        "id": "q1Vxo8skssTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.11"
      ],
      "metadata": {
        "id": "Lh3UPS3Ts3BG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bigrams(sents, ug_count_dic):\n",
        "    bg_dic = collections.defaultdict(float)\n",
        "    for sen in sents:\n",
        "        sen = sen.split(' ')\n",
        "        for i in range(len(sen)-1):\n",
        "            if (sen[i], sen[i+1]) not in bg_dic:\n",
        "                bg_dic[(sen[i],sen[i+1])] = 1\n",
        "            else:\n",
        "                bg_dic[(sen[i],sen[i+1])] += 1\n",
        "    for bi in bg_dic:\n",
        "        bg_dic[bi] = bg_dic[bi]/ug_count_dic[bi[0]]\n",
        "    return bg_dic"
      ],
      "metadata": {
        "id": "gASfApI6tGGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['<s> I am Sam </s>','<s> Sam I am </s>', '<s> I am Sam </s>', '<s> I do not like green eggs and Sam </s>']\n",
        "ug_count_dic, ug_prob_dic = unigram(text)\n",
        "bi_dic = bigrams(text, ug_count_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx9xu9-_tXPs",
        "outputId": "a5a4cd6f-265f-4586-e7cc-1d648324f597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'float'>, {('<s>', 'I'): 3, ('I', 'am'): 3, ('am', 'Sam'): 2, ('Sam', '</s>'): 3, ('<s>', 'Sam'): 1, ('Sam', 'I'): 1, ('am', '</s>'): 1, ('I', 'do'): 1, ('do', 'not'): 1, ('not', 'like'): 1, ('like', 'green'): 1, ('green', 'eggs'): 1, ('eggs', 'and'): 1, ('and', 'Sam'): 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ug_sorted_dic = {x:v for x,v in sorted(ug_prob_dic.items(), key=lambda item:item[1], reverse=True)}\n",
        "print(ug_sorted_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UBentjRuBT-",
        "outputId": "638efa78-b124-4ec0-9f0d-1062c0cacf19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<s>': 0.16, 'I': 0.16, 'Sam': 0.16, '</s>': 0.16, 'am': 0.12, 'do': 0.04, 'not': 0.04, 'like': 0.04, 'green': 0.04, 'eggs': 0.04, 'and': 0.04}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bi_sorted_dic = {x:v for x,v in sorted(bi_dic.items(), key=lambda item:item[1], reverse=True)}\n",
        "print(bi_sorted_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G4tqrORvR1g",
        "outputId": "ecc0baa8-974f-4aec-951c-25bdd56a710d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('do', 'not'): 1.0, ('not', 'like'): 1.0, ('like', 'green'): 1.0, ('green', 'eggs'): 1.0, ('eggs', 'and'): 1.0, ('and', 'Sam'): 1.0, ('<s>', 'I'): 0.75, ('I', 'am'): 0.75, ('Sam', '</s>'): 0.75, ('am', 'Sam'): 0.6666666666666666, ('am', '</s>'): 0.3333333333333333, ('<s>', 'Sam'): 0.25, ('Sam', 'I'): 0.25, ('I', 'do'): 0.25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_ppl(text, bi_dic):\n",
        "  sent = text.split(' ')\n",
        "  ppl = 1\n",
        "  for i in range(1,len(sent)-2):\n",
        "      w1, w2 = sent[i], sent[i+1]\n",
        "      ppl *= bi_dic[(w1,w2)]\n",
        "  return pow(ppl, -1/(len(sent)-2))"
      ],
      "metadata": {
        "id": "-OTEHa_avjGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in text:\n",
        "  print(cal_ppl(t, bi_dic))\n",
        "  print(t, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYgv46hnwBj3",
        "outputId": "f954d5ea-f95e-442b-84f6-5c270a63fc10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2599210498948732\n",
            "<s> I am Sam </s> \n",
            "\n",
            "1.7471609294725976\n",
            "<s> Sam I am </s> \n",
            "\n",
            "1.2599210498948732\n",
            "<s> I am Sam </s> \n",
            "\n",
            "1.189207115002721\n",
            "<s> I do not like green eggs and Sam </s> \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.12"
      ],
      "metadata": {
        "id": "_SPKNLer9n1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pow((0.91**9)*0.01, -1/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iG3uqc09IFt",
        "outputId": "6b2ae872-0836-458f-db15-8c7d8e2627aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7252925496828495"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CAP 4**"
      ],
      "metadata": {
        "id": "TF3jOJuY9p7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2"
      ],
      "metadata": {
        "id": "jly0KfOBLTDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'comedy':[['fun, couple, love, love'], ['couple, fly, fast, fun, fun']],\n",
        "    'action':[['fast, furious, shoot'], ['furious, shoot, shoot, fun'], ['fly, fast, shoot, love']]\n",
        "}\n",
        "\n",
        "D = 'fast, couple, shoot, fly'"
      ],
      "metadata": {
        "id": "KTh9KdoI9slq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unnest(lists):\n",
        "  return list(chain(*lists))"
      ],
      "metadata": {
        "id": "z61CSgzeOqmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "from itertools import chain\n",
        "import math\n",
        "\n",
        "def Bayesian_train(data, binary = False):\n",
        "\n",
        "  def binary_bayes_w_count(data, w):\n",
        "    ocurrances_w = 0\n",
        "    for d in unnest(data):\n",
        "        if w in d:\n",
        "          ocurrances_w += 1\n",
        "    ocurrances_w += 1\n",
        "    return ocurrances_w\n",
        "\n",
        "  clases = list(data.keys())\n",
        "\n",
        "  Pc = {}\n",
        "  likelihood = {}\n",
        "\n",
        "  for c in clases:\n",
        "    sents = unnest(data.values())\n",
        "\n",
        "    N = len(sents)\n",
        "    Nc = len(data[c])\n",
        "\n",
        "    Pc[c] = math.log10(Nc/N)\n",
        "\n",
        "    V = set(', '.join(unnest(sents)).split(', '))\n",
        "\n",
        "    big_doc = ', '.join(unnest(data[c])).split(', ')\n",
        "\n",
        "    for w in V:\n",
        "      if binary:\n",
        "        ocurrances_w = binary_bayes_w_count(data[c], w)\n",
        "        ocurrances_t = len(unnest(data[c])) + len(V) #este denominador podria estar mal\n",
        "      else:\n",
        "        ocurrances_w = big_doc.count(w) +1\n",
        "        ocurrances_t = sum([1 for w in big_doc if w in V]) + len(V)\n",
        "      \n",
        "      p_w_c = math.log10(ocurrances_w/ocurrances_t)\n",
        "\n",
        "      likelihood[w,c] = p_w_c\n",
        "\n",
        "      print(f'Assigned {(w,c)} = {p_w_c} because {ocurrances_w} / {ocurrances_t}\\n')\n",
        "    \n",
        "  return Pc, likelihood, V"
      ],
      "metadata": {
        "id": "hTJD52E5L0fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Pc, likelihood, V = Bayesian_train(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWn5c9EPQmt7",
        "outputId": "0eb10f59-a2c3-4f7f-9d3f-8df7e87375eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assigned ('poor', 'pos') = -0.7781512503836436 because 2 / 12\n",
            "\n",
            "Assigned ('great', 'pos') = -0.3010299956639812 because 6 / 12\n",
            "\n",
            "Assigned ('good', 'pos') = -0.4771212547196625 because 4 / 12\n",
            "\n",
            "Assigned ('poor', 'neg') = -0.18905623622004886 because 11 / 17\n",
            "\n",
            "Assigned ('great', 'neg') = -0.7533276666586115 because 3 / 17\n",
            "\n",
            "Assigned ('good', 'neg') = -0.7533276666586115 because 3 / 17\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "\n",
        "def Bayesian_pred(data, likelihood, V, D):\n",
        "\n",
        "  clases = list(data.keys())\n",
        "  suma = {}\n",
        "\n",
        "  for c in clases:\n",
        "    suma[c] = Pc[c]\n",
        "\n",
        "    for w in D.split(' '): # cambiar split a comas si es necesario\n",
        "      if w in V:\n",
        "        print(f'Summed {likelihood[w,c]} to {c} because {w} in test D.')\n",
        "        suma[c] += likelihood[w,c]\n",
        "  print(suma)\n",
        "  return max(suma, key=suma.get)"
      ],
      "metadata": {
        "id": "41zubrtcTmpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = Bayesian_pred(data, likelihood, V, D)\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "CmZMTkiWV5yb",
        "outputId": "a93fa520-63a1-4e1f-aaf5-70e7df7dfd2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summed -0.4771212547196625 to pos because good in test D.\n",
            "Summed -0.4771212547196625 to pos because good in test D.\n",
            "Summed -0.3010299956639812 to pos because great in test D.\n",
            "Summed -0.7781512503836436 to pos because poor in test D.\n",
            "Summed -0.7533276666586115 to neg because good in test D.\n",
            "Summed -0.7533276666586115 to neg because good in test D.\n",
            "Summed -0.7533276666586115 to neg because great in test D.\n",
            "Summed -0.18905623622004886 to neg because poor in test D.\n",
            "{'pos': -2.431363764158988, 'neg': -2.6708879858122394}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3"
      ],
      "metadata": {
        "id": "crSP4eP9c7Gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'pos':[['good, good, good, great, great, great'], ['poor, great, great']],\n",
        "    'neg':[['good, poor, poor, poor'], ['good, poor, poor, poor, poor, poor, great, great'], ['poor, poor']]\n",
        "}\n",
        "\n",
        "D = 'a good good plot and great characters but poor acting'"
      ],
      "metadata": {
        "id": "vMNvR_58c8X1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Pc, likelihood, V = Bayesian_train(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_3-98w6p8P7",
        "outputId": "c5a2bb06-d218-4ac1-850e-fff3db71ee07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assigned ('poor', 'pos') = -0.7781512503836436 because 2 / 12\n",
            "\n",
            "Assigned ('great', 'pos') = -0.3010299956639812 because 6 / 12\n",
            "\n",
            "Assigned ('good', 'pos') = -0.4771212547196625 because 4 / 12\n",
            "\n",
            "Assigned ('poor', 'neg') = -0.18905623622004886 because 11 / 17\n",
            "\n",
            "Assigned ('great', 'neg') = -0.7533276666586115 because 3 / 17\n",
            "\n",
            "Assigned ('good', 'neg') = -0.7533276666586115 because 3 / 17\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = Bayesian_pred(data, likelihood, V, D)\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "4SIUe53ceLLX",
        "outputId": "7f15822b-45f4-42cd-8a7b-a99931a818d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summed -0.4771212547196625 to pos because good in test D.\n",
            "Summed -0.4771212547196625 to pos because good in test D.\n",
            "Summed -0.3010299956639812 to pos because great in test D.\n",
            "Summed -0.7781512503836436 to pos because poor in test D.\n",
            "Summed -0.7533276666586115 to neg because good in test D.\n",
            "Summed -0.7533276666586115 to neg because good in test D.\n",
            "Summed -0.7533276666586115 to neg because great in test D.\n",
            "Summed -0.18905623622004886 to neg because poor in test D.\n",
            "{'pos': -2.431363764158988, 'neg': -2.6708879858122394}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary\n",
        "Pc, likelihood, V = Bayesian_train(data, binary = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BujMS0e8n4J5",
        "outputId": "6d81713f-1431-4cb6-aed4-27110818c583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assigned ('poor', 'pos') = -0.3979400086720376 because 2 / 5\n",
            "\n",
            "Assigned ('great', 'pos') = -0.22184874961635637 because 3 / 5\n",
            "\n",
            "Assigned ('good', 'pos') = -0.3979400086720376 because 2 / 5\n",
            "\n",
            "Assigned ('poor', 'neg') = -0.17609125905568127 because 4 / 6\n",
            "\n",
            "Assigned ('great', 'neg') = -0.4771212547196625 because 2 / 6\n",
            "\n",
            "Assigned ('good', 'neg') = -0.3010299956639812 because 3 / 6\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = Bayesian_pred(data, likelihood, V, D)\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "sICu9JHun5ZU",
        "outputId": "70eaf172-34bb-41cc-c025-d25d3a86ced2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summed -0.3979400086720376 to pos because good in test D.\n",
            "Summed -0.3979400086720376 to pos because good in test D.\n",
            "Summed -0.22184874961635637 to pos because great in test D.\n",
            "Summed -0.3979400086720376 to pos because poor in test D.\n",
            "Summed -0.3010299956639812 to neg because good in test D.\n",
            "Summed -0.3010299956639812 to neg because good in test D.\n",
            "Summed -0.4771212547196625 to neg because great in test D.\n",
            "Summed -0.17609125905568127 to neg because poor in test D.\n",
            "{'pos': -1.813608784304507, 'neg': -1.4771212547196626}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CAP 5**"
      ],
      "metadata": {
        "id": "1by1zKbu6YwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.1"
      ],
      "metadata": {
        "id": "dnQkIzTp6aRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "bZRvAEuk6c68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "200**0.75"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xA68PaWBnKXD",
        "outputId": "80c6befb-a534-4d3e-c618-408d7a9e79c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53.182958969449885"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CAP 8**"
      ],
      "metadata": {
        "id": "mWXNkFva7BQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.1"
      ],
      "metadata": {
        "id": "rHwVO9V77EPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time"
      ],
      "metadata": {
        "id": "xNWbOuWl7Du7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading corpus\n",
        "nltk.download('treebank')\n",
        "tagged_sentences = nltk.corpus.treebank.tagged_sents()"
      ],
      "metadata": {
        "id": "xq4P_Kid7DkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ac6611-b57f-4549-8a32-8cc8bc1c5694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting test and train dataset\n",
        "train , test = train_test_split(tagged_sentences, shuffle=True, test_size=0.2) "
      ],
      "metadata": {
        "id": "kJ3IskgD_7dZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline Tagger\n",
        "class BaselineTagger():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def train_bl(self, train_pairs):\n",
        "    print(f'Training with {len(train_pairs)} sentences.\\n')\n",
        "    start = time.time()\n",
        "    self.word_dic = word_dic = {}\n",
        "    for sent in train_pairs:\n",
        "      for word, tag in sent:\n",
        "        if word not in self.word_dic:\n",
        "          self.word_dic[word] = {tag:1}\n",
        "        else:\n",
        "          self.word_dic[word] = add_one(self.word_dic[word], tag)\n",
        "    print(f'Training finished. It took {round((time.time()-start),3)} seconds.\\n')\n",
        "\n",
        "  def predict_bl(self, word):\n",
        "    if word in self.word_dic:\n",
        "      result = max(self.word_dic[word], key=self.word_dic[word].get)\n",
        "    else:\n",
        "      result = 'NN'\n",
        "    return result\n",
        "  \n",
        "  def test_bl(self, test_pairs):\n",
        "    score = 0\n",
        "    count = 0\n",
        "    for sent in test_pairs:\n",
        "      for word, tag in sent:\n",
        "        count += 1\n",
        "        prediction = self.predict(word)\n",
        "        gold_label = tag\n",
        "        score += (prediction == gold_label)\n",
        "        if count%500 == 0:print(f'Acc: {round((score/count),3)}, {count} words tested.\\n')\n",
        "\n",
        "  # Helper\n",
        "  def add_one(self, dic, key):\n",
        "    if key in dic.keys():\n",
        "      dic[key] += 1\n",
        "    else:\n",
        "      dic[key] = 1\n",
        "    return dic"
      ],
      "metadata": {
        "id": "BrOUctYvAhD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "bl = BaselineTagger()\n",
        "bl.train(train)\n",
        "bl.test(test)"
      ],
      "metadata": {
        "id": "z-MikMhoEc0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.5\n",
        "\n",
        "Hidden Markov Model (HMM) and Viterbi Algorithm"
      ],
      "metadata": {
        "id": "QqxI4BpeyJwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HMM(BaselineTagger):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  def train_hmm(self, train_set):\n",
        "    print(f'Training with {len(train_set)} sentences.\\n')\n",
        "    start = time.time()\n",
        "    self.train_set = train_set\n",
        "    self.starting_prob = self.build_C()\n",
        "    self.transition_prob = self.build_A()\n",
        "    self.obs_lh = self.build_B()\n",
        "    self.bl = BaselineTagger() # baseline_tagger for if all p = 0\n",
        "    self.bl.train_bl(self.train_set)\n",
        "    print(f'Training finished. It took {round((time.time()-start),3)} seconds.\\n')\n",
        "    \n",
        "  def build_C(self): # Starting prob (C)\n",
        "    starting_prob = {}\n",
        "    for sent in self.train_set:\n",
        "      word, tag = sent[0]\n",
        "      starting_prob = self.add_one(starting_prob, tag)\n",
        "    # Normalising\n",
        "    total = sum(starting_prob.values())\n",
        "    starting_prob = {k: v / total for k, v in starting_prob.items()}\n",
        "    return starting_prob\n",
        "\n",
        "  def build_A(self): # Transition prob (A)\n",
        "      transition_prob = {}\n",
        "      for sent in self.train_set:\n",
        "        for i, (word, tag) in enumerate(sent[:-1]):\n",
        "          next_tag = sent[+1][-1]\n",
        "          if tag not in transition_prob:\n",
        "            transition_prob[tag] = {next_tag:1}\n",
        "          else:\n",
        "            transition_prob[tag] = self.add_one(transition_prob[tag], next_tag)\n",
        "      # Normalising\n",
        "      for key in transition_prob:\n",
        "        total = sum(transition_prob[key].values())\n",
        "        transition_prob[key] = {k: v / total for k, v in transition_prob[key].items()}\n",
        "      return transition_prob\n",
        "  \n",
        "  def build_B(self): # Observation Likelihood (B)\n",
        "    obs_lh = {}\n",
        "    for sent in self.train_set:\n",
        "      for word, tag in sent:\n",
        "        if tag not in obs_lh:\n",
        "          obs_lh[tag] = {word:1}\n",
        "        else:\n",
        "          obs_lh[tag] = self.add_one(obs_lh[tag], word)\n",
        "    # Normalising\n",
        "    for key in obs_lh:\n",
        "      total = sum(obs_lh[key].values())\n",
        "      obs_lh[key] = {k: v / total for k, v in obs_lh[key].items()}\n",
        "    return obs_lh\n",
        "\n",
        "  \n",
        "  def predict_hmm(self, test_set):\n",
        "    score = 0\n",
        "    count = 0\n",
        "\n",
        "    for ind, sent in enumerate(test_set):\n",
        "      N = len(self.starting_prob)\n",
        "      T = len(sent)\n",
        "      matrix = np.zeros((N,T))\n",
        "      possible_tags = []\n",
        "\n",
        "      # First column\n",
        "      first_column = []\n",
        "      first_word = sent[0][0]\n",
        "      for key, value in self.starting_prob.items():\n",
        "        possible_tags.append(key)\n",
        "        if first_word in self.obs_lh[key]:\n",
        "          first_column.append(value * self.obs_lh[key][first_word])\n",
        "        else:\n",
        "          first_column.append(0.0)\n",
        "      matrix[:,0] = first_column\n",
        "\n",
        "      # Rest of the matrix\n",
        "      for t in range(1,T):\n",
        "        word, tag = sent[t]\n",
        "        for s in range(N):\n",
        "          s_tag = possible_tags[s]\n",
        "          candidates = []\n",
        "          for s2 in range(N):\n",
        "            s2_tag = possible_tags[s2]\n",
        "            if matrix[s2,t-1] > 0.0 and s_tag in self.transition_prob[s2_tag] and word in self.obs_lh[s_tag]:\n",
        "              candidates.append(matrix[s2,t-1] * self.transition_prob[s2_tag][s_tag] * self.obs_lh[s_tag][word])\n",
        "            else:\n",
        "              candidates.append(0.0)\n",
        "            matrix[s,t] = max(candidates)\n",
        "\n",
        "      # Prediction\n",
        "      for col in range(matrix.shape[-1]):\n",
        "        count += 1\n",
        "        gold_label = sent[col][-1]\n",
        "\n",
        "        max_val = max(matrix[:,col])\n",
        "        max_ind = list(matrix[:,col]).index(max_val)\n",
        "\n",
        "        if max_val > 0:\n",
        "          predicted = possible_tags[max_ind]\n",
        "          score += (predicted == gold_label)\n",
        "        else:\n",
        "          predicted = self.bl.predict_bl(sent[col])\n",
        "        score += (predicted == gold_label)\n",
        "        \n",
        "      if count%200==0:print(f'Acc: {round((score/count),3)}, {count} words tested.')"
      ],
      "metadata": {
        "id": "Eis-Wma0X9Zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hmm = HMM()\n",
        "hmm.train_hmm(train)\n",
        "hmm.predict_hmm(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6cPMHC_dnjC",
        "outputId": "7c679bce-fdd0-4675-beb8-9285176b6abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with 3131 sentences.\n",
            "\n",
            "Training with 3131 sentences.\n",
            "\n",
            "Training finished. It took 0.147 seconds.\n",
            "\n",
            "Acc: 0.548, 12000 words tested.\n",
            "Acc: 0.552, 13000 words tested.\n",
            "Acc: 0.549, 19500 words tested.\n",
            "Acc: 0.551, 20000 words tested.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CAP 10**\n",
        "10.1"
      ],
      "metadata": {
        "id": "vi1Ut7WQnixm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gold_standar = 'witness for the past,'\n",
        "translation = 'past witness'\n",
        "\n",
        "total_unigrams_produced = 11\n",
        "total_bigrams_produced = 9\n",
        "\n",
        "unigram_precition = 11/11\n",
        "unigram_recall = 11/18\n",
        "\n",
        "bigram_precition = 9/9\n",
        "bigram_recall = 9/17\n",
        "\n",
        "total_precition = (unigram_precition + bigram_precition) / 2\n",
        "total_recall = (unigram_recall + bigram_recall) / 2\n",
        "\n",
        "\n",
        "def chrF(B, total_precition, total_recall):\n",
        "   B = B**2\n",
        "   return ((B+1) * total_precition * total_recall) / (B * total_precition + total_recall)\n",
        "                                                      \n",
        "B = 2\n",
        "chrF(B, total_precition, total_recall)"
      ],
      "metadata": {
        "id": "SIR799pVqfOE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}